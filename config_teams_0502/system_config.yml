# Main System Configuration (v1.3 compatible)

config_locations:
  personas_dir: "personas" # Relative path to personas dir
  schemas_dir: "schemas"   # Relative path to schemas dir

llm_config:
  providers:
    # Keep your existing provider definitions here (anthropic, openai, etc.)
    # Example:
    anthropic:
      api_base: "https://api.anthropic.com"
      context_length: 200000
      env_var: "ANTHROPIC_API_KEY"
      default_model: "claude-3-5-sonnet-20241022"
      valid_models:
        - "claude-3-7-sonnet-20250219"
        - "claude-3-5-sonnet-20241022"
        - "claude-3-opus-20240229"
        - "claude-3-sonnet-20240229"
        - "claude-3-haiku-20240307"
      extended_thinking:
        enabled: false
        budget_tokens: 32000
      litellm_params:
        retry: true
        max_retries: 5
        timeout: 30
        backoff:
          initial_delay: 1
          max_delay: 30
          exponential: true
    openai:
      # ... (Your OpenAI config) ...
    gemini:
      # ... (Your Gemini config) ...
    xai:
      # ... (Your XAI config) ...

  default_provider: "anthropic"
  default_model: "claude-3-opus-20240229" # Example default

  # Base structure/schema definition for personas
  # Actual definitions are in the personas/ directory
  personas:
    provider: null
    model: null
    temperature: 0.7
    extended_thinking:
      enabled: true
    prompts:
      system: null
      user: null
    execution_plan:
      enabled: false
      steps: []
    model_params:
      max_tokens: 4096
    # Add other common fields if needed

# Orchestration using the new factory model
orchestration:
  enabled: true
  entry_team: "discovery"
  max_total_teams: 30
  max_recursion_depth: 5
  error_handling:
    retry_teams: true
    max_retries: 2
    log_level: "ERROR"
  teams:
    discovery:
      name: "Discovery Team"
      tasks:
        - name: "discovery_task_1" # Unique instance name
          agent_type: "generic_single_shot"
          persona_key: "discovery_v1" # References personas/discovery_v1.yml
          requires_approval: false
          max_retries: 2
      routing:
        default: "solution"

    solution:
      name: "Solution Design Team"
      tasks:
        - name: "solution_design_task_1" # Unique instance name
          agent_type: "generic_single_shot"
          persona_key: "solution_designer_v1" # References personas/solution_designer_v1.yml
          requires_approval: true
          max_retries: 1
      routing:
        rules:
          - condition:
              task: "solution_design_task_1"
              status: "success"
            next_team: "coder"
        default: "fallback"

    coder:
      name: "Coder Team"
      tasks:
        - name: "coder_task_1" # Unique instance name
          # Assuming coder might need orchestration
          agent_type: "generic_orchestrating"
          persona_key: "coder_v1" # References personas/coder_v1.yml
          requires_approval: true
          max_retries: 1
      routing:
        default: null # End workflow

    fallback:
      name: "Fallback Team"
      tasks:
        - name: "fallback_coder_task_1" # Unique instance name
          agent_type: "generic_orchestrating"
          persona_key: "coder_v1" # Reuse coder persona
          config: # Task-specific override
            temperature: 0 # Make fallback more conservative
      routing:
        default: null

# Runtime configuration
runtime:
  workflow:
    storage:
      enabled: true
      root_dir: "workspaces/workflows"
      format: "yymmdd_hhmm_{workflow_id}"
      retention:
        max_runs: 10
        max_days: 30
      error_handling:
        ignore_storage_errors: true
        log_level: "ERROR"
  lineage: # Note: Lineage config might also belong under llm_config.personas in v1.3 base structure
    enabled: true
    namespace: "c4h_agents"
    separate_input_output: true
    backend:
      type: "file"
      path: "workspaces/lineage"
    error_handling:
      ignore_failures: true
      log_level: "ERROR"
    context:
      include_metrics: true
      include_token_usage: true
      record_timestamps: true
    retry:
      enabled: true
      max_attempts: 3
      initial_delay: 1
      max_delay: 30
      backoff_factor: 2
      retry_on:
        - "overloaded_error"
        - "rate_limit_error"
        - "timeout_error"

# Backup settings
backup:
  enabled: true
  path: "workspaces/backups"

# Logging configuration
logging:
  level: "debug"
  format: "structured"
  agent_level: "debug"
  providers:
    anthropic:
      level: "debug"
    openai:
      level: "debug"
  truncate:
    prefix_length: 2000
    suffix_length: 1000
